import { getCustomStaticPath } from '@/utils/getCustomStaticPath';

export const meta = {
  title: 'Identify entities from images',
  description: 'Learn how to identify entities from an image using Amplify.',
  platforms: [
    'swift',
    'javascript',
    'angular',
    'nextjs',
    'react',
    'vue'
  ]
};

export const getStaticPaths = async () => {
  return getCustomStaticPath(meta.platforms);
};

export function getStaticProps(context) {
  return {
    props: {
      meta
    }
  };
}

<Callout informational>

**Note:** Make sure to complete the [getting started](../set-up-predictions) section first, where you will set up the IAM roles with the right policy actions

</Callout>


## Working with the API

<InlineFilter filters={['swift']}>

In order to match entities from a pre-created [Amazon Rekognition Collection](https://docs.aws.amazon.com/rekognition/latest/dg/collections.html), ensure that both `collectionId` and `maxEntities` are set in your `amplifyconfiguration.json` file. The value of `collectionId` should be the name of your collection that you created either with the CLI or the SDK. The value of `maxEntities` should be a number greater than `0` or less than `51` (50 is the max number of entities Rekognition can detect from a collection). If both `collectionId` and `maxEntities` do not have valid values in the `amplifyconfiguration.json` file, then this call will just detect entities in general with facial features, landmarks, etc. Bounding boxes for entities are returned as ratios so make sure if you would like to place the bounding box of your entity on an image that you multiple the x by the width of the image, the y by the height of the image, and both height and width ratios by the image's respective height and width.

You can identify entity matches from your Rekognition Collection in your app using the following code sample:

<BlockSwitcher>

<Block name="Async/Await">

```swift
func detectEntities(_ image: URL) async throws -> [Predictions.Entity] {
    do {
        let result = try await Amplify.Predictions.identify(.entities, in: image)
        print("Identified entities: \(result.entities)")
        return result.entities
    } catch let error as PredictionsError {
        print("Error identifying entities: \(error)")
        throw error
    } catch {
        print("Unexpected error: \(error)")
        throw error
    }
  }
}
```

</Block>

<Block name="Combine">

```swift
func detectEntities(_ image: URL) -> AnyCancellable {
    Amplify.Publisher.create {
        try await Amplify.Predictions.identify(.entities, in: image)
    }
    .sink(receiveCompletion: { completion in
        if case let .failure(error) = completion {
            print("Error identifying entities: \(error)")
        }
    }, receiveValue: { value in
        print("Identified entities: \(value.entities)")
    })
}
```

</Block>

</BlockSwitcher>

### Detecting Celebrities

To detect celebrities you can pass in `.detectCelebrity` in the `type:` field. Results are mapped to `IdentifyCelebritiesResult`. For example:

<BlockSwitcher>

<Block name="Async/Await">

```swift
func detectCelebrities(_ image: URL) async throws -> [Predictions.Celebrity] {
    do {
        let result = try await Amplify.Predictions.identify(.celebrities, in: image)
        let celebrities = result.celebrities
        let celebritiesNames = celebrities.map(\.metadata.name)
        print("Identified celebrities with names: \(celebritiesNames)")
        return celebrities
    } catch let error as PredictionsError {
        print("Error identifying celebrities: \(error)")
        throw error
    } catch {
        print("Unexpected error: \(error)")
        throw error
    }
}
```

</Block>

<Block name="Combine">

```swift
func detectCelebrities(_ image: URL) -> AnyCancellable {
    Amplify.Publisher.create {
        try await Amplify.Predictions.identify(.celebrities, in: image)
    }
    .sink(receiveCompletion: { completion in
        if case let .failure(error) = completion {
            print("Error identifying celebrities: \(error)")
        }
    }, receiveValue: { value in
        print("Identified celebrities with names: \(value.celebrities.map(\.metadata.name))")
    })
}
```

</Block>

</BlockSwitcher>


</InlineFilter>

<InlineFilter filters={['javascript','angular','nextjs','react','vue']}>

`Predictions.identify({entities: {...}}) => Promise<>`
Detects entities from an image and potentially related information such as position, faces, and landmarks. Can also identify celebrities and entities that were previously added. This function returns a Promise that returns an object with the entities that was identified.  

Input can be sent directly from the browser (using File object or ArrayBuffer object) or an Amazon S3 key from project bucket.

Detect entities directly from image uploaded from the browser. (File object)

```javascript
import { Predictions } from '@aws-amplify/predictions';

const response = await Predictions.identify({
  entities: {
    source: {
      file,
    },
  }
});
console.log({ response });
```

Detect entities directly from image binary from the browser. (ArrayBuffer object)
This technique is useful when you have base64 encoded binary image data, for example, from a webcam source.

```javascript
import { Predictions } from '@aws-amplify/predictions';

const response = await Predictions.identify({
  entities: {
    source: {
      bytes: imageArrayBuffer,
    },
  }
});
console.log({ response });
```

From Amazon S3 key
```javascript
import { Predictions } from '@aws-amplify/predictions';

const response = await Predictions.identify({
  entities: {
    source: {
      key: pathToPhoto,
      level: 'guest' | 'private' | 'protected', //optional, default is the configured on Storage category
    },
  }
});
console.log({ response });
```

The following options are independent of which `source` is specified. For demonstration purposes it will be used `file` but it can be used S3 Key as well. 

Detecting bounding box of faces from an image with its landmarks (eyes, mouth, nose).

```javascript
import { Predictions } from '@aws-amplify/predictions';

const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
  }
})
for (const { boundingBox, landmarks } of entities) {
  const { 
    width, // ratio of overall image width
    height, // ratio of overall image height
    left, // left coordinate as a ratio of overall image width
    top // top coordinate as a ratio of overall image height
  } = boundingBox;
  
  for(const landmark of landmarks) {
    const {
      type, // string "eyeLeft", "eyeRight", "mouthLeft", "mouthRight", "nose"
      x, // ratio of overall image width
      y // ratio of overall image height
    } = landmark;
  }
}
```

Detecting celebrities on an image. It will return only celebrities the name and urls with related information.

```javascript
import { Predictions } from '@aws-amplify/predictions';

const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
    celebrityDetection: true // boolean. It will only show detected celebrities 
  }
})

for(const { boundingBox, landmarks, metadata } of entities) {
  const { 
    name,
    urls 
  } = metadata; // celebrity info
  
  // ...
}
.catch(err => console.log({ err }));
```

Detecting entities from previously uploaded images (e.g. Advanced Configuration for Identify Entities)

```javascript
import { Predictions } from '@aws-amplify/predictions';

const { entities } = await Predictions.identify({
  entities: {
    source: {
      file,
    },
    collection: true
  }
})

for({ boundingBox, metadata } of entities) {
  const {
    width, // ratio of overall image width
    height, // ratio of overall image height
    left, // left coordinate as a ratio of overall image width
    top // top coordinate as a ratio of overall image height
  } = boundingBox;
  const { externalImageId } = metadata; // this is the object key on S3 from the original image
}
```
</InlineFilter>
