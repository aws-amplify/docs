## uploadData

The `uploadData` method uploads files into Amazon S3.

```typescript
import { uploadData } from 'aws-amplify/storage';

try {
	const response = await uploadData({
		key: filename,
		data: file,
		options: {
			accessLevel: 'private' | 'protected' | 'guest', // defaults to `guest`
			targetIdentityId: string, // id of another user, if `level: protected`
			onProgress, // Optional progress callback.
		},
	});
	console.log('Key from Response: ', response?.result?.key);
} catch (error) {
	console.log('Error : ', error);
}
```

### Public level

```typescript
import { uploadData } from 'aws-amplify/storage';

try {
	const response = await uploadData({
		key: filename,
		data: file,
		options: {
			accessLevel: 'guest',
		},
	});
	console.log('Key from Response: ', response?.result?.key);
} catch (error) {
	console.log('Error : ', error);
}
```

### Protected level of same user

```typescript
import { uploadData } from 'aws-amplify/storage';

try {
	const response = await uploadData({
		key: filename,
		data: file,
		options: {
			accessLevel: 'protected',
		},
	});
	console.log('Key from Response: ', response?.result?.key);
} catch (error) {
	console.log('Error : ', error);
}
```

### Protected level of another user

```typescript
import { uploadData } from 'aws-amplify/storage';

try {
const response = await uploadData({
				key: filename,
				data: file,
				options: {
                      accessLevel: 'protected' 
                      targetIdentityId: 'XXXXXXX', // other user identityId
			}});
  console.log('Key from Response: ', response?.result?.key);
} catch(error){
  console.log('Error : ', error)
}

```
### Private level

```typescript
import { uploadData } from 'aws-amplify/storage';

try {
	const response = await uploadData({
		key: filename,
		data: file,
		options: {
			accessLevel: 'private',
		},
	});
	console.log('Key from Response: ', response?.result?.key);
} catch (error) {
	console.log('Error : ', error);
}
```

### Monitor progress of upload

To track the progress of your upload, you can use the `onProgress` in options:

```typescript
import { uploadData } from 'aws-amplify/storage';

const response = uploadData({
	key: filename,
	data: file,
	options: {
		onProgress: ({ transferredBytes, totalBytes }) => {
			if (totalBytes) {
				console.log(
					`Upload progress ${(transferredBytes / totalBytes) * 100} %`
				);
			}
		},
	},
});
console.log('Key from Response: ', response?.result?.key);
```

## Pause and resume upload

We have callback functions that support resume, pause and cancel of `uploadData'. 

```typescript 
import { uploadData } from 'aws-amplify/storage';

// Pause and resume a task
const uploadTask = uploadData({ key, data: file });
//...
uploadTask.pause();
//...
uploadTask.resume();
//...
await uploadTask.result;
```

## Cancel upload

```typescript
import { uploadData } from 'aws-amplify/storage';

const uploadTask = uploadData({ key, data: file });
//...
uploadTask.cancel();
try {
	await uploadTask.result;
} catch (error) {
	if (isCancelError(error)) {
		// Handle error thrown by task cancellation
	}
}

```

Other options available are:

```typescript
import { uploadData } from 'aws-amplify/storage'; 

uploadData({ key, data: file, options:  {
  contentType?: "text/html", // (String) The default content-type header value of the file when downloading it.
  contentEncoding?: "compress" // (String) The default content-encoding header value of the file when downloading it.
  contentDisposition?: "attachment", // (String) Specifies presentational information for the object
  metadata?: {key: "value"}, // (map<String>) A map of metadata to store with the object in S3.
  useAccelerateEndpoint?: boolean; // Whether to use accelerate endpoint.
}});

```

<!-- TODO Rewrite why do we not have multi-part upload documented for JS? -->

When a page refresh occurs during the upload, re-initializing the upload with the same file will continue from previous progress point.

<Callout>

Uploads that were initiated over one hour ago will be cancelled automatically. There are instances (e.g device went offline, user logs out) where the incomplete file remains in your S3 account. It is recommended to [setup a s3 lifecycle rule](https://aws.amazon.com/blogs/aws-cloud-financial-management/discovering-and-deleting-incomplete-multipart-uploads-to-lower-amazon-s3-costs/) to automatically cleanup incomplete upload requests.

</Callout>

<Callout>

Currently, the `onProgress` event is dependent and based on the number of parts that are sent to S3. Currently, the library uploads at about 5 MB per part. If you upload a file smaller than this, the event will not be fired.

</Callout>

